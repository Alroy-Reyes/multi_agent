2025-06-12 20:01:31,167	INFO worker.py:1724 -- Started a local Ray instance.
2025-06-12 20:01:33,535	INFO tune.py:592 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
C:\Users\USER\OneDrive\Desktop\multi_agent_timetabling\marl_env\Lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
C:\Users\USER\OneDrive\Desktop\multi_agent_timetabling\marl_env\Lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
C:\Users\USER\OneDrive\Desktop\multi_agent_timetabling\marl_env\Lib\site-packages\gymnasium\utils\passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
C:\Users\USER\OneDrive\Desktop\multi_agent_timetabling\marl_env\Lib\site-packages\gymnasium\utils\passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
2025-06-12 20:01:33,914	WARNING tune.py:916 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
[36m(PPO pid=22372)[0m Install gputil for GPU system monitoring.
+--------------------------------------------------------+
| Configuration for experiment     PPO_Timetabling       |
+--------------------------------------------------------+
| Search algorithm                 BasicVariantGenerator |
| Scheduler                        FIFOScheduler         |
| Number of trials                 1                     |
+--------------------------------------------------------+

View detailed results here: C:/Users/USER/ray_results/PPO_Timetabling
To visualize your results with TensorBoard, run: `tensorboard --logdir C:/Users/USER/ray_results/PPO_Timetabling`

Trial status: 1 PENDING
Current time: 2025-06-12 20:01:34. Total running time: 0s
Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+--------------------------------------------+
| Trial name                        status   |
+--------------------------------------------+
| PPO_timetabling_env_fc112_00000   PENDING  |
+--------------------------------------------+

Trial PPO_timetabling_env_fc112_00000 started with configuration:
+---------------------------------------------------------------------------+
| Trial PPO_timetabling_env_fc112_00000 config                              |
+---------------------------------------------------------------------------+
| _AlgorithmConfig__prior_exploration_config                                |
| _disable_action_flattening                                          False |
| _disable_execution_plan_api                                          True |
| _disable_initialize_loss_from_dummy_batch                           False |
| _disable_preprocessor_api                                           False |
| _enable_new_api_stack                                               False |
| _fake_gpus                                                          False |
| _is_atari                                                                 |
| _learner_class                                                            |
| _rl_module_spec                                                           |
| _tf_policy_handles_more_than_one_loss                               False |
| action_mask_key                                               action_mask |
| action_space                                                              |
| actions_in_input_normalized                                         False |
| always_attach_evaluation_results                                    False |
| auto_wrap_old_gym_envs                                               True |
| batch_mode                                              complete_episodes |
| callbacks                                            ...efaultCallbacks'> |
| checkpoint_trainable_policies_only                                  False |
| clip_actions                                                        False |
| clip_param                                                            0.3 |
| clip_rewards                                                              |
| compress_observations                                               False |
| count_steps_by                                                  env_steps |
| create_env_on_driver                                                False |
| custom_eval_function                                                      |
| delay_between_worker_restarts_s                                       60. |
| disable_env_checking                                                 True |
| eager_max_retraces                                                     20 |
| eager_tracing                                                        True |
| enable_async_evaluation                                             False |
| enable_connectors                                                    True |
| enable_tf1_exec_eagerly                                             False |
| entropy_coeff                                                          0. |
| entropy_coeff_schedule                                                    |
| env                                                       timetabling_env |
| env_runner_cls                                                            |
| env_task_fn                                                               |
| evaluation_config                                                         |
| evaluation_duration                                                    10 |
| evaluation_duration_unit                                         episodes |
| evaluation_interval                                                       |
| evaluation_num_workers                                                  0 |
| evaluation_parallel_to_training                                     False |
| evaluation_sample_timeout_s                                          180. |
| exploration_config/type                                StochasticSampling |
| explore                                                              True |
| export_native_model_files                                           False |
| fake_sampler                                                        False |
| framework                                                           torch |
| gamma                                                                0.99 |
| grad_clip                                                                 |
| grad_clip_by                                                  global_norm |
| ignore_worker_failures                                              False |
| in_evaluation                                                       False |
| input                                                             sampler |
| keep_per_episode_custom_metrics                                     False |
| kl_coeff                                                              0.2 |
| kl_target                                                            0.01 |
| lambda                                                                 1. |
| local_gpu_idx                                                           0 |
| local_tf_session_args/inter_op_parallelism_threads                      8 |
| local_tf_session_args/intra_op_parallelism_threads                      8 |
| log_level                                                            WARN |
| log_sys_usage                                                        True |
| logger_config                                                             |
| logger_creator                                                            |
| lr                                                                  0.001 |
| lr_schedule                                                               |
| max_num_worker_restarts                                              1000 |
| max_requests_in_flight_per_sampler_worker                               2 |
| metrics_episode_collection_timeout_s                                  60. |
| metrics_num_episodes_for_smoothing                                    100 |
| min_sample_timesteps_per_iteration                                      0 |
| min_time_s_per_iteration                                                  |
| min_train_timesteps_per_iteration                                       0 |
| model/_disable_action_flattening                                    False |
| model/_disable_preprocessor_api                                     False |
| model/_time_major                                                   False |
| model/_use_default_native_models                                       -1 |
| model/always_check_shapes                                           False |
| model/attention_dim                                                    64 |
| model/attention_head_dim                                               32 |
| model/attention_init_gru_gate_bias                                    2.0 |
| model/attention_memory_inference                                       50 |
| model/attention_memory_training                                        50 |
| model/attention_num_heads                                               1 |
| model/attention_num_transformer_units                                   1 |
| model/attention_position_wise_mlp_dim                                  32 |
| model/attention_use_n_prev_actions                                      0 |
| model/attention_use_n_prev_rewards                                      0 |
| model/conv_activation                                                relu |
| model/conv_filters                                                        |
| model/custom_action_dist                                                  |
| model/custom_model                                                        |
| model/custom_preprocessor                                                 |
| model/dim                                                              84 |
| model/encoder_latent_dim                                                  |
| model/fcnet_activation                                               tanh |
| model/fcnet_hiddens                                            [256, 256] |
| model/framestack                                                     True |
| model/free_log_std                                                  False |
| model/grayscale                                                     False |
| model/lstm_cell_size                                                  256 |
| model/lstm_use_prev_action                                          False |
| model/lstm_use_prev_action_reward                                      -1 |
| model/lstm_use_prev_reward                                          False |
| model/max_seq_len                                                      20 |
| model/no_final_linear                                               False |
| model/post_fcnet_activation                                          relu |
| model/post_fcnet_hiddens                                               [] |
| model/use_attention                                                 False |
| model/use_lstm                                                      False |
| model/vf_share_layers                                               False |
| model/zero_mean                                                      True |
| normalize_actions                                                    True |
| num_consecutive_worker_failures_tolerance                             100 |
| num_cpus_for_driver                                                     1 |
| num_cpus_per_learner_worker                                             1 |
| num_cpus_per_worker                                                     1 |
| num_envs_per_worker                                                     1 |
| num_gpus                                                                0 |
| num_gpus_per_learner_worker                                             0 |
| num_gpus_per_worker                                                     0 |
| num_learner_workers                                                     0 |
| num_sgd_iter                                                           30 |
| num_workers                                                             0 |
| observation_filter                                               NoFilter |
| observation_fn                                                            |
| observation_space                                                         |
| offline_sampling                                                    False |
| ope_split_batch_by_episode                                           True |
| output                                                                    |
| output_compress_columns                                ['obs', 'new_obs'] |
| output_max_file_size                                             67108864 |
| placement_strategy                                                   PACK |
| policies/cma_0                                       ...Discrete(10), {}) |
| policies/cma_1                                       ...Discrete(10), {}) |
| policies/saha_0                                      ... Discrete(5), {}) |
| policies/saha_1                                      ... Discrete(5), {}) |
| policies_to_train                                                         |
| policy_map_cache                                                       -1 |
| policy_map_capacity                                                   100 |
| policy_mapping_fn                                    ...00000131E3E93240> |
| policy_states_are_swappable                                         False |
| postprocess_inputs                                                  False |
| preprocessor_pref                                                deepmind |
| recreate_failed_workers                                             False |
| remote_env_batch_wait_ms                                                0 |
| remote_worker_envs                                                  False |
| render_env                                                          False |
| replay_sequence_length                                                    |
| restart_failed_sub_environments                                     False |
| rollout_fragment_length                                                 1 |
| sample_async                                                           -1 |
| sample_collector                                     ...leListCollector'> |
| sampler_perf_stats_ema_coef                                               |
| seed                                                                      |
| sgd_minibatch_size                                                      6 |
| shuffle_buffer_size                                                     0 |
| shuffle_sequences                                                    True |
| simple_optimizer                                                       -1 |
| sync_filters_on_rollout_workers_timeout_s                             60. |
| synchronize_filters                                                    -1 |
| tf_session_args/allow_soft_placement                                 True |
| tf_session_args/device_count/CPU                                        1 |
| tf_session_args/gpu_options/allow_growth                             True |
| tf_session_args/inter_op_parallelism_threads                            2 |
| tf_session_args/intra_op_parallelism_threads                            2 |
| tf_session_args/log_device_placement                                False |
| torch_compile_learner                                               False |
| torch_compile_learner_dynamo_backend                             inductor |
| torch_compile_learner_dynamo_mode                                         |
| torch_compile_learner_what_to_compile                ...ile.FORWARD_TRAIN |
| torch_compile_worker                                                False |
| torch_compile_worker_dynamo_backend                                onnxrt |
| torch_compile_worker_dynamo_mode                                          |
| train_batch_size                                                        6 |
| update_worker_filter_stats                                           True |
| use_critic                                                           True |
| use_gae                                                              True |
| use_kl_loss                                                          True |
| use_worker_filter_stats                                              True |
| validate_workers_after_construction                                  True |
| vf_clip_param                                                         10. |
| vf_loss_coeff                                                          1. |
| vf_share_layers                                                        -1 |
| worker_cls                                                             -1 |
| worker_health_probe_timeout_s                                          60 |
| worker_restore_timeout_s                                             1800 |
+---------------------------------------------------------------------------+[36m(PPO pid=22372)[0m 2025-06-12 20:02:02,921	WARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!
2025-06-12 20:02:55,024	WARNING util.py:202 -- The `process_trial_result` operation took 4.915 s, which may be a performance bottleneck.
2025-06-12 20:02:55,025	WARNING util.py:202 -- Processing trial results took 4.916 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2025-06-12 20:02:55,025	WARNING util.py:202 -- The `process_trial_result` operation took 4.917 s, which may be a performance bottleneck.
[36m(PPO pid=22372)[0m C:\Users\USER\OneDrive\Desktop\multi_agent_timetabling\marl_env\Lib\site-packages\ray\rllib\utils\torch_utils.py:310: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\ReduceOps.cpp:1839.)
[36m(PPO pid=22372)[0m   y_var = torch.var(y, dim=[0])
[36m(PPO pid=22372)[0m C:\Users\USER\OneDrive\Desktop\multi_agent_timetabling\marl_env\Lib\site-packages\ray\rllib\utils\torch_utils.py:311: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\ReduceOps.cpp:1839.)
[36m(PPO pid=22372)[0m   diff_var = torch.var(y - pred, dim=[0])


Trial status: 1 RUNNING
Current time: 2025-06-12 20:02:04. Total running time: 30s
Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+--------------------------------------------+
| Trial name                        status   |
+--------------------------------------------+
| PPO_timetabling_env_fc112_00000   RUNNING  |
+--------------------------------------------+
Trial status: 1 RUNNING
Current time: 2025-06-12 20:02:34. Total running time: 1min 0s
Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                        status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| PPO_timetabling_env_fc112_00000   RUNNING        11            29.8469    182    23.8182                     24                     22              16.5455                      1 |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
Trial status: 1 RUNNING
Current time: 2025-06-12 20:03:04. Total running time: 1min 30s
Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                        status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| PPO_timetabling_env_fc112_00000   RUNNING        20            54.4017    337      23.05                     24                     13                16.85                      1 |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
Trial status: 1 RUNNING
Current time: 2025-06-12 20:03:34. Total running time: 2min 0s
Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                        status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| PPO_timetabling_env_fc112_00000   RUNNING        28             81.259    472    22.8214                     24                     13              16.8571                      1 |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
Trial status: 1 RUNNING
Current time: 2025-06-12 20:04:04. Total running time: 2min 30s
Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                        status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| PPO_timetabling_env_fc112_00000   RUNNING        39            111.261    656     22.359                     24                     -7              16.8205                      1 |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
Trial status: 1 RUNNING
Current time: 2025-06-12 20:04:34. Total running time: 3min 0s
Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                        status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| PPO_timetabling_env_fc112_00000   RUNNING        49            139.546    829    22.3469                     24                     -7              16.9184                      1 |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

Trial PPO_timetabling_env_fc112_00000 completed after 50 iterations at 2025-06-12 20:04:35. Total running time: 3min 1s
+--------------------------------------------------------+
| Trial PPO_timetabling_env_fc112_00000 result           |
+--------------------------------------------------------+
| episodes_total                                      50 |
| num_env_steps_sampled                              845 |
| num_env_steps_trained                              845 |
| sampler_results/episode_len_mean                  16.9 |
| sampler_results/episode_reward_mean              22.38 |
+--------------------------------------------------------+

Trial status: 1 TERMINATED
Current time: 2025-06-12 20:04:48. Total running time: 3min 14s
Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                        status         iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| PPO_timetabling_env_fc112_00000   TERMINATED       50            142.266    845      22.38                     24                     -7                 16.9                      1 |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

